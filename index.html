<!doctype html>
<html>

<head>
  <title>YouTube Classification</title>
  <meta name="viewport" content="user-scalable=no, initial-scale=1, maximum-scale=1, minimum-scale=1">
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="js/menu.js"></script>
  <style>
    .menu-index {
      color: rgb(255, 255, 255) !important;
      opacity: 1 !important;
      font-weight: 700 !important;
    }
  </style>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="content">
      <div class="content-table flex-column">
        <!--Start Intro-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <img class="image" src="img/harvard.png">
          </div>
          <div class="flex-item flex-column">
            <p class="text text-medium">
              <a target="_blank" href="https://www.linkedin.com/in/dylanrandle/">Dylan Randle</a> <br>
              <a target="_blank" href="https://www.linkedin.com/in/thomas-hill-862a6093/">Tommy Hill</a><br>
              <a target="_blank" href="https://www.linkedin.com/in/filip-michalsky-72772280/">Filip Michalsky</a><br>
              <a target="_blank" href="https://www.linkedin.com/in/paxton-maeder-york-00108736/">Paxton Maeder-York</a><br>
            </p>
          </div>
        </div>
        <div class="flex-row">
          <div class="flex-item flex-column">
            <p class="text add-top-margin">
              We propose Youtube video classification at scale, leveraging a dataset of over 8 million videos
              with high throughput computing and large data handling system design. The project requires training
              on 1.5 terabytes of video and audio files to then predict a video type from several thousand labels. Our
              solution uses two bidirectional-LSTM networks, one for audio and one for video, trained on a Spark-based
              sitting atop Hadoop YARN and enabled by Elephas: a library that enables training Tensorflow models
              in Spark. The infrastructure used consists of a custom cluster of m4.xlarge instances on AWS using Amazon
              Machine Images to spin-up nodes with the correct software dependencies. We found this approach produced
              reliable systemic speedup and effective classification with our final model.<br/><br/>

              We have learned many lessons through this project, especially in provisioning our custom Elastic Map Reduce
              cluster, as well as in building various software dependencies: Tensorflow-Spark connector for reading
              TFRecord files, Amazon-flavored Linux, Apache Maven, and getting all of our various components to be
              version-compatible (e.g. Scala, Java versions with PySpark, Tensorflow-Spark and Amazon Linux versions).
              We faced many issues in provisioning the cluster as a result of the growing complexity that so many software
              dependencies adds to the problem, especially when there are non-backward-compatible components (e.g. PySpark
              with Scala).<br/><br/>

              In the future, we would recommend not using Amazon Machine Images (AMIs) for provisioning, and instead bundling
              the Python-based dependencies into jar files (a method which we found was possible only after the fact). This
              would certainly save much time as there are many specific "gotchas" that are required for tackling the AMI
              method successfully (EBS volume configuration, must be Amazon Linux, etc.). On the positive side, we found that
              asynchronous weight updates can be parallelized highly effectively, and we actually achieved superlinear speedup
              with this  method. Future work may involve training more complex models (e.g. multiple input models), or
              implementing alternative parallel Stochastic Gradient Descent schemes (e.g. Baidu's proposed Ring AllReduce).<br/><br/>

              We hope that you can learn from our work and the particular method we employed to deploy Tensorflow model training
              on a massive dataset by utilizing Spark sitting atop a Hadoop-based elastic cluster. Please check out the source
              code <a href="https://github.com/filip-michalsky/cs205_spring19_final_project">here</a>.<br/><br/>
            </p>
          </div>
        </div>
        <!--End Intro-->

      </div>
    </div>
  </div>
</body>

</html>
